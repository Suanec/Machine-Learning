# 机器学习的流程与专业术语

### 什么是机器学习

**当经验以数据形式存储**，研究**算法**使得计算机可以从经验数据中学习，学习到的结果**(模型)**是可以对新情况**(更好地)** 完成**某个任务**。

训练经验E   性能标准P    任务T

###数据集

要进行机器学习，首先要有数据，这里我们又了一批关于西瓜的数据记录。这组记录的集合称为一个“数据集”(data set)

###示例/样本

数据集里每条记录对应关于一个对象（这里是西瓜）的描述，称为一个“示例”(instance)或“样本”(sample)

###属性/特征

每个样本对应的数据都反应了对象在某方面的表现或性质，例如“色泽”。这称为“属性”(attribute) 或“特征”(feature).

###属性值/特征值

每个样本对应的数据都反应了对象在某方面的表现或性质，例如“色泽”。这称为“属性”(attribute) 或“特征”(feature).某个特定样本对应的数据在某个属性上的值称为“属性值”或“特征值”。

###属性空间/特征空间

当我们用d个属性来表示一个对象。这d个属性相当于d个维度将张成一个d维的“属性空间”/“特征空间”。而每个样本对应的数据就是这个空间中的一个点，即一个n维向量，称为“特征向量”。

###标签/标记

机器学习的任务通常是对某些未知的信息（例如好瓜or坏瓜）做“预测”。用来标识样本关于未知信息的信息项成为“标签”。
“标签”的取值空间称为“标签空间”或“输出空间”。({0,1})

###训练/学习

从数据中学的模型的过程称为“学习”(learning)或“训练”(training), 这个过程通过执行某个算法来完成。

###训练数据

训练过程中使用的数据称为训练数据，其中每个样本称为训练样本。训练样本组成的集合称为训练集。

###测试

学得模型后，使用其进行预测的过程称为“测试”。被预测的样本称为“测试样本”

###分类/回归

当我们是用带有真实标签的训练集去学习到一个模型预测某些样本的标签。若我们欲预测标签的是离散值，此类学习任务称为“分类”，若欲预测的是连续值，此类学习任务称为“回归”。

###聚类

当我们的训练数据集中没有关于标签的信息。我们的任务是将训练集根据算法划分成若干个分组（“簇”）。这一任务将有助于我们了解数据内在的规律，以便更深入地分析数据。这样的学习任务称为“聚类”。

###监督学习/无监督学习

训练数据中有标记信息
-----监督学习(Supervised learning)
训练数据中没有标记信息
-----无监督学习(Unsupervised learning)

###强化学习

探索如何让机器在学习如何将场景（环境状态）映射到动作，以获取最大的奖赏。
例如探索如何让机器在种瓜过程中不断探索，最终总结出优秀种瓜策略

![image](https://github.com/LinglingGreat/Quote/blob/master/img/ML/ml1.png)

# 模型评估

## 什么是满意的模型/假设

### 泛化能力

机器学习的目标是使学得的模型能很好地适用于“新样本”，而不是仅仅在训练样本上工作得很好。即使对聚类这样的无监督学习任务，也希望学得的簇划分能适用于没在训练集中出现的样本。
模型适用于新样本的能力，成为“泛化”(generalization) 能力。

####对训练集的偏好：

希望训练集能学习到适用于整个样本空间的假设。训练集作为样本空间的一个采样，能够很好地样本空间的全局特性。
假设样本空间中的样本服从一个未知分布
1.获得的训练样本都是独立地从这个分布上采样获得的，即“独立同分布”(independent and identically distributed, 简称i.i.d.)
2.样本数量尽可能多

####对假设和经验一致性的偏好：

对于新样本的预测标签与其真实标签尽可能一致（泛化误差低）

对于训练样本的预测标签与其真实标签尽可能一致（训练误差低）

为了对模型的泛化误差进行估计，通常将带标签的样本集抽取一部分出来作为“测试集”，其余作“训练集”，以在“测试集”上的“测试误差”作为“泛化误差”的近似。

####对假设复杂度的偏好：

“奥卡姆剃刀”（Occam’s razor）:
若有多个假设与观察一致，则选最简单的那个。
“简单有效原理”
“切勿浪费较多东西去做，用较少的东西，同样可以做好的事情。”

“没有免费的午餐”No free lunch theorem
All models are wrong, but some models are useful. —George Box
A set of assumptions that works well in one domain may work poorly in another

不要脱离了实际问题谈算法效果

## 效果度量

### 均方误差、错误率、精度

![image](https://github.com/LinglingGreat/Quote/blob/master/img/ML/ml2.png)

### 查准率、查全率、PR图、F1分数

**推荐系统中常用到 **

“判断为不会违约的申请中有多少比例会违约”
“所有不会违约的申请中有多少比例被挑了出来”

根据其真实类别与学习器预测类别的组合划分：
真正例(true positive)、假正例(falsepositive)、真反例(true negative)、假反例(falsenegative)
令TP、FP、TN、FN分别表示对应的样例数(TP+FP+TN+FN=样例总数)
定义：分类结果的“混淆矩阵”(confusion matrix)

![image](https://github.com/LinglingGreat/Quote/blob/master/img/ML/ml3.png)

| 真实情况 |  预测结果  |            |
| :------: | :--------: | :--------: |
|          |    正例    |    反例    |
|   正例   | TP(真正例) | FN(假反例) |
|   反例   | FP(假正例) | TN(真反例) |

按照某个学习器预测结果对样例进行排序
按照顺序逐个把样本作为正例进行预测
每次可以计算出当前的查全率、查准率
以查准率为纵轴、查全率为横轴做图，就得到了查准率-查全率曲线，简称“P-R曲线”

![image](https://github.com/LinglingGreat/Quote/blob/master/img/ML/ml4.png)

### 真/假正例率、ROC曲线、AUC

![image](https://github.com/LinglingGreat/Quote/blob/master/img/ML/ml5.png)

按照某个学习器预测结果对样例进行排序
按照顺序逐个把样本作为正例进行预测
每次计算出TPR与FPR，分别以它们为横、纵坐标作图

![image](https://github.com/LinglingGreat/Quote/blob/master/img/ML/ml6.png)

### 代价敏感

在现实任务重常常会遇到情况：不同类型的错误所造成的后果不同
为权衡不同类型错误所造成的不同损失，我们为不同的错误赋予“非均等代价”(unequal cost)：
根据任务的领域知识设定一个“代价矩阵”(cost matrix)：

![image](https://github.com/LinglingGreat/Quote/blob/master/img/ML/ml7.png)

##训练集和测试集的划分

###留出法

![image](https://github.com/LinglingGreat/Quote/blob/master/img/ML/ml8.png)

不同训练/测试集的划分将导致不同的评估结果。
单次使用留出法得到的估计结果往往不够稳定可靠。
故一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。

### 交叉验证法

![image](https://github.com/LinglingGreat/Quote/blob/master/img/ML/ml9.png)



